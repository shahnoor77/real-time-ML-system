# Let's build a class called Predictor
# that does the following:
# - Loads the model artifact from the registry
# - Runs inference on the input data, so it also need to fetch the necessary data from
# the feature store.

# The class should have the following methods:
# - __init__: loads the model artifact from the registry
# - predict: runs inference on the input data
# - class method to load model artifact and return an instance of this class
import json
import pickle
from typing import List
#from dotenv import load_dotenv

import pandas as pd
from loguru import logger
from pydantic import BaseModel

from src.data_preprocessing import interpolate_missing_candles
from src.feature_engineering import add_features
from src.utils import get_model_name
from tools.ohlc_data_reader import OhlcDataReader
#load_dotenv()

class PredictorOutput(BaseModel):
    """
    A Pydantic model to represent the output of the Predictor class
    """

    price_change_prediction: float
    price_prediction: float
    current_price: float
    product_id: str
    current_ts_ms: int
    current_ts: str
    predicted_ts: str

    # add a method to return a dictionary representation of the object
    def to_dict(self):
        return {
            'price_change_prediction': self.price_change_prediction,
            'price_prediction': self.price_prediction,
            'current_price': self.current_price,
            'product_id': self.product_id,
            'current_ts_ms': self.current_ts_ms,
            'current_ts': self.current_ts,
            'predicted_ts': self.predicted_ts,
        }


class Predictor:
    def __init__(
        self,
        model_path: str,
        ohlc_window_sec: int,
        feature_view_name: str,
        feature_view_version: int,
        product_id: str,
        last_n_minutes: int,
        features_to_use: List[str],
        prediction_window_sec: int,
    ):
        self.model = self._load_model_pickle(model_path)

        self.ohlc_data_reader = OhlcDataReader(
            ohlc_window_sec=ohlc_window_sec,
            feature_view_name=feature_view_name,
            feature_view_version=feature_view_version,
        )

        self.ohlc_window_sec = ohlc_window_sec
        self.product_id = product_id
        self.last_n_minutes = last_n_minutes
        self.features_to_use = features_to_use
        self.prediction_window_sec = prediction_window_sec

    @classmethod
    def from_model_registry(cls, product_id: str, status: str) -> 'Predictor':
        """
        Fetches the model artifact from the model registry, and all the relevant
        metadata we need to make predictions from this model artifact, and return a
        Predictor object.

        Steps:
        1. Load the model artifact from the model registry
        2. Fetch the relevant metadata from the model registry
        3. Return a Predictor object with the model artifact and the metadata

        Args:
            - product_id: the product_id of the model we want to fetch
            - status: the status of the model we want to fetch, for example "production"

        Returns:
            - Predictor: an instance of the Predictor class with the model artifact and
            the metadata fetched from the model registry
        """
        import os

        from comet_ml.api import API

        comet_api = API(api_key=os.environ['COMET_ML_API_KEY'])

        # Step 1: Download the model artifact from the model registry
        model = comet_api.get_model(
            workspace=os.environ['COMET_ML_WORKSPACE'],
            model_name=get_model_name(product_id),
        )
        # find the version for the current model with the given `status`
        # As for dev, or staging, you can have multiple versions, so we sort by
        # version and get the latest one.
        model_versions = model.find_versions(status=status)
        # sort the model versions list from high to low and pick the first element
        model_version = sorted(model_versions, reverse=True)[0]

        # download the model artifact for this `model_version`
        model.download(version=model_version, output_folder='./')
        # TODO: this name should be generated by the same function, that is called in the training pipeline
        model_path = './lasso_model.pkl'

        # Step 2: Fetch the relevant metadata from the model registry
        # find the experiment associated with this model
        experiment_key = model.get_details(version=model_version)['experimentKey']

        # get the experiment
        experiment = comet_api.get_experiment_by_key(experiment_key)

        # get all the parameters we need from the experiment
        # - ohlc_window_sec: int,
        # - feature_view_name: str,
        # - feature_view_version: int,
        # - product_id: str,
        # - last_n_minutes: int,
        # - features_to_use: List[str],
        # - prediction_window_sec: int,
        ohlc_window_sec = int(
            experiment.get_parameters_summary('ohlc_window_sec')['valueCurrent']
        )
        feature_view_name = experiment.get_parameters_summary('feature_view_name')[
            'valueCurrent'
        ]
        feature_view_version = int(
            experiment.get_parameters_summary('feature_view_version')['valueCurrent']
        )
        product_id = experiment.get_parameters_summary('product_id')['valueCurrent']

        # TODO: last_n_minutes is a parameter that should be log in the experiment when
        last_n_minutes = 30

        # features_to_use is a list of strings, so we need to parse the str that Comet ML returns
        features_to_use = json.loads(
            experiment.get_parameters_summary('features_to_use')['valueCurrent']
        )
        prediction_window_sec = int(
            experiment.get_parameters_summary('prediction_window_sec')['valueCurrent']
        )

        # Step 3: Return a Predictor object with the model artifact and the metadata
        return cls(
            model_path=model_path,
            ohlc_window_sec=ohlc_window_sec,
            feature_view_name=feature_view_name,
            feature_view_version=feature_view_version,
            product_id=product_id,
            last_n_minutes=last_n_minutes,
            features_to_use=features_to_use,
            prediction_window_sec=prediction_window_sec,
        )

    def predict(self) -> PredictorOutput:
        """
        Generates a prediction using the model in `self.model`
        and the latest data in the feature store

        Steps:
        1. Fetch the latest data from the feature store
        2. Preprocess the data (add missing candles). I need to follow
        the exact same preprocessing steps I used to train the model
        3. model.predict(X) where X is the preprocessed data

        Returns:
            - PredictorOutput: a Pydantic model with the prediction
        """
        # Step 1: Fetch the latest data from the feature store
        logger.debug('Fetching OHLC data from the online feature store')
        ohlc_data = self.ohlc_data_reader.read_from_online_store(
            product_id=self.product_id,
            last_n_minutes=self.last_n_minutes,
        )
        ohlc_data['datetime'] = pd.to_datetime(ohlc_data['timestamp'], unit='ms')

        # Step 2: Preprocess the data
        logger.debug('Preprocessing the data - adding missing candles')
        ohlc_data = interpolate_missing_candles(ohlc_data, self.ohlc_window_sec)

        logger.debug('Preprocessing the data - adding features')
        n_candles_into_future = self.prediction_window_sec // self.ohlc_window_sec
        ohlc_data = add_features(ohlc_data, n_candles_into_future=n_candles_into_future)

        logger.debug(
            'Preprocessing the data - keeping features in `self.features_to_use`'
        )
        X = ohlc_data[self.features_to_use]

        # Step 3. Model predict
        logger.debug('Running inference on the preprocessed data')
        price_change_prediction = self.model.predict(X)[-1]

        # get the current price
        current_price = ohlc_data['close'].iloc[-1]

        # calculate the price prediction
        price_prediction = current_price * (1 + price_change_prediction)

        # get the element from the prediction array
        # and create a PredictorOutput object
        # with the prediction and the product_id
        # and the timestamp of the last candle
        current_ts_ms = ohlc_data['timestamp'].iloc[-1]
        predicted_ts_ms = current_ts_ms + self.prediction_window_sec * 1000

        # transform current_ts_ms and predicted_ts_ms to datetime strings in UTC
        current_ts = pd.to_datetime(current_ts_ms, unit='ms').strftime(
            '%Y-%m-%d %H:%M:%S'
        )
        predicted_ts = pd.to_datetime(predicted_ts_ms, unit='ms').strftime(
            '%Y-%m-%d %H:%M:%S'
        )

        # breakpoint()

        return PredictorOutput(
            price_change_prediction=price_change_prediction,
            price_prediction=price_prediction,
            current_price=current_price,
            product_id=self.product_id,
            current_ts_ms=current_ts_ms,
            current_ts=current_ts,
            predicted_ts=predicted_ts,
        )

    def _load_model_pickle(self, model_path: str):
        # load the model using pickle using a with context manager
        with open(model_path, 'rb') as f:
            return pickle.load(f)


if __name__ == '__main__':
    # No need to re-run this, as we already checked it works
    # logger.debug('Running the Predictor class with hardcoded values')
    # predictor = Predictor(
    #     model_path='/Users/paulabartabajo/src/real-time-ml-system-cohort-1/services/price_predictor/lasso_model.pkl',
    #     ohlc_window_sec=60,
    #     feature_view_name='ohlc_feature_view',
    #     feature_view_version=10,
    #     product_id='BTC/USD',
    #     features_to_use=[
    #         'rsi',
    #         'momentum',
    #         'std',
    #         'MACD',
    #         'MACD_Signal',

    #         'last_observed_target',

    #         'day_of_week',
    #         'hour_of_day',
    #         'minute_of_hour',
    #     ],
    #     prediction_window_sec=60*5,
    # )
    # prediction = predictor.predict()
    # logger.debug(f'Prediction: {prediction}')

    logger.debug(
        'Running the Predictor class with the from_model_registry class method'
    )
    predictor = Predictor.from_model_registry(
        product_id='BTC/USD',
        status='production',
    )
    prediction = predictor.predict()
    logger.debug(f'Prediction: {prediction}')